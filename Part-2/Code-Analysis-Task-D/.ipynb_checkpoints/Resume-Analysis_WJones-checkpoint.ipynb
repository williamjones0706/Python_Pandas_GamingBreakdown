{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does.\n",
    "\n",
    "The counter from collections keeps track or counts how many times equivalent values or values that are exactly the same are added. So, if the letter B is in a list 10 times the counter would return that [B:10] (B is present 10 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. Think about how the `REQUIRED_SKILLS` set and the `DESIRED_SKILLS` set can be used in the program. Also, why are the variables in ALL CAPS?]_\n",
    "\n",
    "The resume_path is assigned the path going back one directory or folder so that it can go into the resources folder and get the resume text file. The skills variables are in ALL CAPS because they are being assigned as constant variables that do not change, like asigning 3.14 to the variable PIE so that it remains constant in the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. How is this function defined? What does it take in, how does it work, and what does it return?]_\n",
    "\n",
    "The code below is defining a function that loads the filepath. Upon loading the filepath it is opened in read mode ('r') and assigned to resume_file_handler. While it is open the resume file handler is read and assigned to a new variable, resume contents. The contents are then all converted to lowercase text using the .lower() command and reassigned to resume_contents. The contents are then split into tokens using the .split() command and returned when the function is called in the module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. What is this cell doing? Is it passing anything? Does it get anything back? What happens to `word_list`?]_\n",
    "\n",
    "In this cell, the resume file path is loaded and stored in a variable called word_list. Nothing is happening with this code yet, but it will be used later in the module to perform other functions as the variable is assigned the loaded text from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* Why is a `set` created?\n",
    "A set is used to store values in a similar manner to a list, it is created so that values can be stored in something for further use.\n",
    "\n",
    "* How are we populating the set\n",
    "The set is being populated by the for loop that references the word_list. For each token (could be called any variable) in the word_list, it is added to the resume set.\n",
    "\n",
    "* Why would it be necessary to create a `punctuation` set?\n",
    "It is necessary to create a puncatuation set because we need to remove punctuation that was read as a whole word from the resume set, but that cannot be done by simply be done by altering the resume set itself. The punctuation set allows us to remove uncessary punction from the resume set in a simple manner and reassign the new set to resume again.\n",
    "\n",
    "* What does subtracting from the set do?\n",
    "Subtracting the punctuation set from the resume set removes any punction contatined in the punctuation set from the resume set. Whatever is different in the resume set remains. The punctuation set includes several common forms of punctuation.\n",
    "\n",
    "* * Refer to the `resume = resume - punctuation` line\n",
    "* What does `\\n` do in a string\n",
    "The '\\n' prints the string but then adds a new line so that the next printed output is on a new line. It makes the visual ouput look cleaner and breaks it into sections as opposed to the resume set following the first string on the same line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'advanced', 'd3,', 'camp', 'web', 'skills', 'to', 'tableau,', 'frank', 'excel.', 'apis.', 'javascript,', 'mongodb', 'front-end', '##', 'databases', 'leaflet.js', 'forecasting', 'git/github', 'mysql', 'n.', 'r,', 'interests', 'html/css,', 'working', 'stein', 'python', '#', 'sql,', 'business', 'creating', 'graduate', 'big', 'mining', 'machine', 'aws', 'statistics,', 'contributing', 'with', 'html,', 'bootstrap,', 'analytics', 'apps', 'analyze', 'performing', 'tables', 'vba', 'in', 'visualizations', 'excel,', 'basic', 'media', 'boot', 'social', 'intelligence', 'from', 'data', 'tableau', 'api', 'visualization', 'mining,', 'writing', 'files', 'education', 'the', 'experience', 'algorithms', 'using', 'designing', 'and', 'python,', 'hadoop,', '*', 'learning,', 'pivot', 'open-source', 'sets', 'developing', 'css,', 'learning', 'software', 'microsoft', 'interactions,', 'statistics', 'd3', 'scripts', 'pandas', 'modeling', 'cloud', 'hadoop'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'advanced', 'd3,', 'camp', 'web', 'skills', 'apis.', 'to', 'tableau,', 'frank', 'javascript,', 'excel.', 'mongodb', 'front-end', '##', 'databases', 'leaflet.js', 'forecasting', 'git/github', 'mysql', 'n.', 'r,', 'interests', 'html/css,', 'working', 'stein', 'python', 'sql,', 'business', 'creating', 'graduate', 'big', 'mining', 'machine', 'aws', 'statistics,', 'contributing', 'with', 'html,', 'bootstrap,', 'analytics', 'apps', 'analyze', 'performing', 'tables', 'vba', 'in', 'visualizations', 'excel,', 'basic', 'media', 'boot', 'social', 'intelligence', 'from', 'data', 'tableau', 'api', 'visualization', 'mining,', 'writing', 'files', 'education', 'the', 'experience', 'algorithms', 'using', 'designing', 'and', 'python,', 'hadoop,', 'learning,', 'pivot', 'open-source', 'sets', 'developing', 'css,', 'learning', 'software', 'microsoft', 'interactions,', 'statistics', 'd3', 'scripts', 'pandas', 'modeling', 'cloud', 'hadoop'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* What does using a `set` intersection do in this section?\n",
    "The set intersection used for the first two print commands ensures that what is printed out on the screen is only that which is present in both of the sets. Anything not common to each is disregarded.\n",
    "\n",
    "* How does the character cleaning function work differently than the word cleaning function? (test it)\n",
    "The first list comprehension cleans out punctuation that was read as a word itself. However, there are words that have punctuation in them was characters within the word. The second list comprehension is a loop within a loop that searches through the characters in each word and removes them if they are in punctuation set.\n",
    "\n",
    "* Can you add more items to the `stop_words` list?\n",
    "Yes, the list can be populated with as many words as are desired. For instance, if you do not want to see the word, data, in the word list, you would simply include it in the stop_words list.\n",
    "\n",
    "* Explain how the list `word_list` list comprehension works. What does it return and what is the filtering criteria?\n",
    "The list comprehension is an elegant way of creating a list that loops through whatever readable item it is told to and returns the values that are specified. It can be a single loop, like the word list punctuation clean up that scans each word in the word list and returns only words that are not in the punctuation set. Or a loop within a loop that loops through each character within each word and returns only the values specified if it is a conditional loop. In these cases the condition was not returning anything in the punctuation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'mysql', 'python', 'statistics'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n.', 'stein', '##', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '##', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel.', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis.', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'front-end', 'web', 'visualizations', 'using', 'html,', 'css,', 'bootstrap,', 'd3,', 'and', 'leaflet.js', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '##', 'skills', 'microsoft', 'excel,', 'python,', 'javascript,', 'html/css,', 'api', 'interactions,', 'social', 'media', 'mining,', 'sql,', 'hadoop,', 'tableau,', 'advanced', 'statistics,', 'machine', 'learning,', 'r,', 'git/github', '##', 'interests', 'contributing', 'to', 'open-source', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html,', 'css,', 'javascript,', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below.\n",
    "Be sure to explain the following:\n",
    "\n",
    "* How was the `word_count` dictionary initialized, what were in initial key values, and how were they set?\n",
    "The word count was initialized with the key valus from the word_list. The deault values for each key were set to 0.\n",
    "\n",
    "* Explain the logic behind incrementing the world count value using the `for loop`. Be sure to explain how to reference the word key in the `word_count` dictionary\n",
    "For each word in the word_list; the loop is reading through each word in the list, and for each word, the key word in the word_count dictionary is increased by 1(word_count[word]+=1) or word_count[word] + 1\n",
    "\n",
    "* Collections.counter is optional, but explain the difference between the `for loop` and using `Counter`\n",
    "There should be no real difference between the counter and loop. Both are adding +1 to the count of each word for each instance it finds. I believe the real difference is that the counter is a more elegent solution. It does not require initializing everything to 0 and passing a variable to a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frank': 1, 'n': 1, 'stein': 1, '': 4, 'education': 1, 'data': 7, 'analytics': 3, 'visualization': 2, 'boot': 1, 'camp': 1, 'graduate': 1, 'experience': 1, 'creating': 1, 'pivot': 1, 'tables': 1, 'vba': 1, 'scripts': 2, 'excel': 2, 'modeling': 1, 'forecasting': 1, 'basic': 1, 'statistics': 2, 'writing': 1, 'python': 4, 'analyze': 1, 'sets': 1, 'from': 1, 'files': 1, 'apis': 1, 'social': 2, 'media': 2, 'mining': 2, 'mysql': 1, 'mongodb': 1, 'databases': 1, 'developing': 1, 'frontend': 1, 'web': 2, 'visualizations': 1, 'html': 2, 'css': 2, 'bootstrap': 1, 'd3': 2, 'leafletjs': 1, 'the': 2, 'tableau': 2, 'business': 1, 'intelligence': 1, 'software': 2, 'performing': 1, 'big': 2, 'hadoop': 2, 'machine': 2, 'learning': 2, 'algorithms': 1, 'skills': 1, 'microsoft': 1, 'javascript': 2, 'htmlcss': 1, 'api': 1, 'interactions': 1, 'sql': 1, 'advanced': 1, 'r': 1, 'gitgithub': 1, 'interests': 1, 'contributing': 1, 'opensource': 1, 'pandas': 1, 'designing': 1, 'apps': 1, 'cloud': 1, 'aws': 1}\n",
      "Counter({'data': 7, '': 4, 'python': 4, 'analytics': 3, 'visualization': 2, 'scripts': 2, 'excel': 2, 'statistics': 2, 'social': 2, 'media': 2, 'mining': 2, 'web': 2, 'html': 2, 'css': 2, 'd3': 2, 'the': 2, 'tableau': 2, 'software': 2, 'big': 2, 'hadoop': 2, 'machine': 2, 'learning': 2, 'javascript': 2, 'frank': 1, 'n': 1, 'stein': 1, 'education': 1, 'boot': 1, 'camp': 1, 'graduate': 1, 'experience': 1, 'creating': 1, 'pivot': 1, 'tables': 1, 'vba': 1, 'modeling': 1, 'forecasting': 1, 'basic': 1, 'writing': 1, 'analyze': 1, 'sets': 1, 'from': 1, 'files': 1, 'apis': 1, 'mysql': 1, 'mongodb': 1, 'databases': 1, 'developing': 1, 'frontend': 1, 'visualizations': 1, 'bootstrap': 1, 'leafletjs': 1, 'business': 1, 'intelligence': 1, 'performing': 1, 'algorithms': 1, 'skills': 1, 'microsoft': 1, 'htmlcss': 1, 'api': 1, 'interactions': 1, 'sql': 1, 'advanced': 1, 'r': 1, 'gitgithub': 1, 'interests': 1, 'contributing': 1, 'opensource': 1, 'pandas': 1, 'designing': 1, 'apps': 1, 'cloud': 1, 'aws': 1})\n",
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. Which column was sorted and how? How was the top ten selected? Does that explain the significance of `[:10]`?\n",
    "\n",
    "The loop is looping through each word in the sorted word_count and using the paramenters of keys from the word_count dictionary and reversing the sorted list to show highest to lowest count. The :10 tells tells the loop to only perform for the first 10 words, :10 is the same as saying from 0 to 9.\n",
    "\n",
    "As a bonus, explain how you would get rid of the blank token.\n",
    "You could assign the sorted words to a list and then use the .drop function to drop the token that does not contain any key word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token:                      Count: 4\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
